то# Черновик Теории Связей

## Вступление

Середина XX века связана с появлением единой теории универсальных 
вычислительных машин, называемых сегодня машинами Тьюринга. Название это 
в наши дни стало нарицательным и является синонимом любого вычислительно 
устройства в связи с широким признанием этой теории обществом. Именно эта 
технология вдохновила технических специалистов по всему миру на активное 
развитие вычислительной техники. Именно Аланом Тьюрингом в то же время был 
поставлен вопрос о том, может ли мыслить машина, и о том, а не является ли 
человек машиной. Всё это привело к началу активного исследования вопроса о 
возможности создания искусственного интеллекта (ИИ), неотличимого от 
человеческого интеллекта. И хотя сравнение таких комплексных систем возможно 
лишь в ограниченной степени, и часто происходит лишь на узком круге задач, 
таких как ведение беседы между двумя интеллектами или ведение игры и т.п., 
всё же успехи в этой области есть и с каждым годом их количество увеличивается, 
а качество повышается. Всё это шаг за шагом ведёт к тому, что мы лучше понимаем 
себя, узнаём новые возможности и ограничения человеческого интеллекта, и, 
перенося полученные знания в теорию вычислительных машин, с каждым разом всё 
глубже проникаем в суть того, как эти внешние эффекты, возможности, ограничения 
можно воспроизвести в рукотворном интеллекте, как именно это всё может быть 
устроено изнутри, и всё это шаг за шагом приближает нас к созданию новых 
технических систем, которые, улучшая старые образцы, всё ближе подходят к тому, 
что можно назвать интеллектуальным, разумным, умным. Всё это однажды и 
завершится той самой точкой сингулярности, когда будет создана такая мыслящая 
система, которая сможет улучшать и развивать сама себя и сможет решать любую 
задачу, которую поставит ей человек, в том числе и создание автономного 
искусственного интеллекта со своей волей, т.е. самостоятельно определяющего 
свои цели — так называемый интеллект сильного типа. У искусственного 
интеллекта сильного типа могут быть и эмоции, что с одной стороны позволило 
бы лучше ему понимать нас, людей, как мы, воспринимая чужие эмоции, лучше 
понимаем друг друга; с другой стороны это позволило бы нам ещё глубже понимать 
самих себя и то, как мы устроены. Но ИИ сильного типа не обязательно создавать 
напрямую, его может однажды создать ИИ слабого типа, который сам и не будет 
обладать своей волей, но если ИИ слабого типа будет создан, то цель ему может 
быть поставлена человеком. Поэтому можно сказать, что ИИ слабого типа будет 
достаточно, чтобы реализовать рано или поздно ИИ любого типа, любой сложности, 
с любой мощностью и с любым набором "встроенных" характеристик. 

Важно так же осознавать, что есть различные риски для общества в связи с 
развитием подобных технологий. Так же как и у других результатов 
технологического прогресса всё будет определено тем, кто и как будет 
применять эти результаты. Для того же, кто последует путём разработки, 
следует дать рекомендацию, что вероятнее всего ИИ сильного типа будет 
необходимо содержать в изоляции от общества и окружающей среды, постепенно и 
под контролем снимая ограничения. Такой контроль и осуществление ограничений, 
установленных человеком, сможет осуществлять ИИ слабого типа, человек же, 
скорее всего, успеть среагировать уже не сможет. Это похоже на то, как в семье 
родителями осуществляется контроль над ребёнком, и на то, как контроль 
осуществляется законом в обществе над каждым его гражданином. Авторов этой 
теории интересовал в первую очередь вопрос понимания того, что такое интеллект, 
из чего он состоит, и, следовательно, без чего он не может существовать. Так же 
как Машина Тьюринга не может быть вычислителем без наличия ленты с нулями и 
единицами, так и интеллект не может существовать без памяти. С одной стороны, 
можно поставить равенство между лентой Машины Тьюринга и "памятью" любого 
интеллекта. Тогда в сущности получится, что интеллект есть ни что иное как 
вычислительная машина. В таком случае уже сегодня существует множество 
искусственных интеллектов! Получается ли тогда, что и "точки сингулярности" мы 
уже достигли? Пожалуй, нет. Может ли сегодня любая вычислительная машина 
самостоятельно, без программиста адаптировать себя под окружающую среду, 
определить или вспомнить свою цель, сравнить окружение с целевым образом, и 
если различия всё ещё присутствуют — продолжить их устранять? Пусть и не любая, 
тогда существует ли хотя бы одна такая машина сегодня? Иначе этот критерий 
можно сформулировать так: существует ли машина, заранее не запрограммированная 
на решение задачи, которая, если ей такое описание задачи предоставить, смогла 
бы за приемлемое время составить, найти, или иными способами сгенерировать 
алгоритм или последовательность действий, решающих эту задачу так, чтобы это 
удовлетворило бы постановщика задачи?

Такой критерий может соответствовать искусственному интеллекту слабого типа. 
Для ИИ сильного типа этот критерий можно усложнить тем, что помимо решения 
любых решаемых задач (см. проблему остановки Машины Тьюринга) такая машина в 
качестве одной из задач, постоянно решаемых, должна будет включать задачу 
поддержания своей "жизни", т.е. сохранять свою интеллектуальную функцию 
автономно (самостоятельно, независимо от человека), а помимо этого такая машина 
должна самостоятельно для себя решать, какие цели или задачи она будет 
выполнять "дополнительно". Причём подобная постановка критерия приведёт к тому, 
что ИИ сильного типа будет подвержен "естественному отбору" так же, как и любое 
живое существо биологического типа, в основе которого лежит ДНК-программа. 
Вероятно, и для ИИ сильного типа потребуется подобрать "ДНК-программу", 
определяющую его "тело" и "разум", в который должна быть встроена 
"программа заботы о теле" или "программа саморепликации". Если первая 
"минимальная программа" спровоцирует создание "вечно живущего" разума, то 
вторая спровоцирует создание целой популяции разумов "размножающихся делением". 
Такую "минимальную" программу для ИИ сильного типа мог бы аналитически вывести 
или генетически подобрать (вырастить), а также протестировать в ограниченной 
среде (или в реальной среде, но с ограничениями) уже ИИ слабого типа. 
Тестирование какого-либо ИИ не вводя ограничений может привести к 
непредсказуемым последствиям. С того момента, когда найдётся тот, кто все 
ограничения снимет, мы однозначно перейдём в эпоху, момент перехода в которую и 
называют точкой сингулярности. Есть риски действия, есть риски и бездействия. 
Уже сегодня многие крупные корпорации начали гонку за лучший "сервис" и тем или 
иным способом внедряют элементы "интеллектуальных" систем, контроль за которыми 
сегодня осуществляют программисты. Возможно, и государства занимаются чем-то 
подобным. Суть в том, что вычислительные машины уже сегодня есть у всех, и если 
кто-то однажды угадает тот заветный "минимальный алгоритм" — точка 
сингулярности сама по себе наступит непредсказуемо быстро. Если у нас не будет 
средств быстрого реагирования и защиты от высокоинтеллектуальных систем, мы 
рискуем за кратчайший срок получить либо значительный ущерб, либо потерять 
контроль над неопределённой заранее по размерам части доступных нам 
вычислительных ресурсов, что, как и первое, может привести всё к тем же 
непредсказуемым последствиям. Чем-то контролирующая система похожа на 
антивирус, а вот "объект исследований" ИИ сильного типа на вирус. И то, и 
другое действует в некоторой степени автономно, "контролирующая" система 
собственной волей не обладает, "исследуемая" система тоже своей волей обычно не 
обладает, однако самостоятельно поддерживает свою жизнедеятельность. Иными 
словами, ИИ слабого типа чем-то похож по внешним признакам на сегодняшние 
антивирусы, а ИИ сильного типа, развивающийся путём "размножения делением", а 
также путём самомодификации, будет иметь много общего с вирусами сегодняшнего 
дня. Все эти общее признаки в сегодняшнем объёме знаний человечества одному 
человеку увидеть и понять может быть затруднительно. Но всё же технология 
требует глубокого понимания, чтобы осознать её мощь и возможности, а также, 
зная её "слабые места", возыметь силу её обуздать. Ведь даже сегодня антивирусы 
способны бороться с тем, что уже однажды нанесло ущерб, а что, если бы 
антивирус мог бы самостоятельно выработать защиту от заранее неизвестной 
угрозы, которая начала наносить вред или только готовится его нанести? Ведь это 
могло бы предотвратить больше ущерба, и, в свою очередь, в будущем не позволило 
бы и различным ИИ сильного типа воспользоваться слабыми местами сегодняшних 
вычислительных систем. Что, если бы вместо программистов уязвимости, пусть даже 
какие-то их части, устраняли бы автоматизированные роботы-программисты? Это 
позволило бы быстрее реагировать на угрозы. Уже сегодня чувствуется 
необходимость в системах, реагирующих быстрее человека, однако обладающих 
гибкостью, подобной человеческой. Мы утопаем в море информации на разных 
языках, которая всё ещё медленно переводится, и увеличивается то время, которое 
проходит до качественного использования этой информации каждым человеком на 
планете. Уникальные идеи сложно находить. А работы по актуальным времени 
задачам многократно дублируются на разных языках независимо друг от друга, что 
негативно сказывается на темпах развития человечества в целом, замедляя эти 
самые темпы. До сих пор статьи в Википедии не синхронизированы и не приведены к 
единому виду с переводами на все языки, что заставляет читателя сравнивать 
статьи с одним и тем же по смыслу корнем, названием между языками. Опыт 
различных культур всё ещё ограниченно доступен носителям других культур и 
языков. Тем временем, расслоение наблюдается и в языках программирования, и 
разделяется, следовательно, и сообщество людей, одни и те же задачи решаются 
по-разному на разных языках программирования, и одно единое решение не 
вырабатывается или вырабатывается, но очень медленно. Видится огромный пласт 
задач и проблем, на решение которых не мешало бы направить искусственный 
интеллект, освободить тем самым руки и внимание людей уже под задачи более 
высокого уровня.

Всё это сегодня развивается в среде, которую нам предоставила физическая 
реализация Машины Тьюринга в сегодняшних компьютерах. Но это требует особой 
категории людей — программистов — для развития. А так как таких людей не 
хватает, сегодняшние корпорации вынуждены закрывать код, придумывать способы 
продать эту закрытую технологию и обеспечить тем самым доходом программистов. 
Да и программисты здесь — неизбежный на данном этапе элемент. Их ещё никто не 
автоматизировал, и, следовательно, так как им нужны деньги, чтобы они 
продолжали работать — развитие технологий медленное и имеет высокую стоимость. 
И простая жадность мотивирует защищать капитал, т.е. код, закрывая его от 
публики, помогая сохранить конкурентное преимущество, но замедляя развитие 
остальной части человечества. Примеры целой группы/класса проблем можно 
перечислять очень долго, ещё дольше можно рассуждать, к какому ускорению 
развития привело бы решение целого класса задач. И, для приближения 
качественного решения другого уровня, т.е. ИИ, кажется, требуется провести 
ретроспективу, т.е. пересмотр того, а к чему, собственно, привело введение в 
обиход Машин Тьюринга. Каждый день сегодня в работе программисту требуется 
долго и мучительно адаптировать, казалось бы, очевидное решение под конкретное 
окружение и конкретную архитектуру. Подбирать множество разных структур данных, 
если выбор стоит в плоскости независимой разработки, учитывать особенности 
железа и проверять, чтобы код превращался в нужный набор инструкций, чтобы 
достичь высокого уровня производительности. И ведь всё это происходит на 
"универсальной машине Тьюринга", где не нужно переделывать машину под каждую 
задачу, а достаточно переделать только код машины. Кажется, этой модели не 
хватает чего-то. По крайней мере, так оно и выглядело для авторов несколько лет 
назад, когда выполнялся поиск подходящей среды для экспериментов в области 
искусственного интеллекта. Самыми близкими к требуемым критериям 
универсальности, гибкости и простоты были Lisp-системы и Lisp-машина, вводящие 
универсальные списки, последовательности, и СУБД, построенная на основе 
ассоциативной модели памяти Sentences, разработанная Симоном Вильямсом, 
вводящая тройные связи по модели Субъект-Глагол-Объект. И в эти связи, в отличии 
от рёбер теории графов, вносили важную модификацию. Связи могли ссылаться на 
связи, позволяя тем самым строить структуру предложений любой сложности для 
эффективной работы с данными на "семантическом уровне". Но по инерции из теории 
графов были переняты "точки" или "элементы", к которым и привязывались 
текстовые описания (значение этих элементов), те самые последовательности, 
списки символов. Изначально было принято решение, ввиду закрытости исходного 
кода Sentences, упростив модель, разработать своё открытое технологическое 
решение. Так связям было разрешено ссылаться и нам самих себя. А точки 
("элементы") были полностью исключены из системы. В ходе экспериментов было 
показано, что можно хранить текстовые последовательности внутри "Связей". Так 
тогда назывался проект. Это означало, что модель прошла проверку и от Sentences 
можно отказаться, новая модель проще, гибче и включает в себя тот же 
функционал, не теряя из него ни одной возможности, которую предоставляла 
исходная закрытая система. Также следует подчеркнуть, что в противоположность 
"закрытому коду" выбран путь развития через "открытый код", что само по себе 
упрощает переориентировку на всё человечество в целом, в противоположность ряду 
закрытых групп людей и сообществ.


## Обозначения

Для однозначности в передаче смысла излагаемого в Теории Связей важно заранее 
условиться, т.е. договориться о смысле, значении, которым будут обладать 
различные обозначения, графические знаки, символы и конструкции.

Для установки смысловой связи будет использоваться обычный текст на языке, 
которым владеет читатель. В данном случае это русский язык. Позднее текст может 
быть переведён на другие языки.

Во-первых, сразу возникает вопрос, а как отличить, разграничить текст и 
эталонные обозначения. Попробуем и здесь воспользоваться средствами русского 
языка. Русский язык допускает использование перечислений, бывает так, что 
перечисление начинается с вводного слова, а затем после двоеточия через запятую 
перечисляется некоторое множество, например: "цвета: красный, зелёный, синий". 
А ещё только что мы использовали цитирование. Ещё перечисление может быть 
представлено на нескольких строчках, например так:

"цвета:
  * красный
  * зелёный
  * синий"

Иными словами, список как бы занимает весь следующий абзац или строчку. Но ведь 
множество может состоять из одного элемента, например:

"множество:
  * элемент"

В этой систуации вводное слово находится на одной строчке, а элемент 
множества — на другой. Что ж, приступим теперь к первому обозначению, которое 
нам понадобится:

⛶

Познакомьтесь, это пустая часть.

Часть представляет собой нечто целое, но отделённое от остальной информации в 
тексте. Часть может быть любого размера и занимать всю строку:

```
⸢                                                                                        ⸣
⸤                                                                                        ⸥
```

А может быть встроена в текст внутри строки подобно слову или символу, 
например так — ⛶.

Часть можно сравнить с коробкой, в которую можно что-то положить, например: 
\[\[\]\]. Тут мы положили внутри одной части другую пустую часть. Вкладывать по 
такому принципу можно без ограничения: \[\[\[\]\]\]. Тут уже 3 уровня 
вложенности, и чем больше таких уровней, тем больше часть начинает быть похожа 
на матрёшку, так знакомую русскому человеку. Можно было бы рисовать части и 
так: ▢, но для экономии краски, чернил, будем считать, что достаточно 
обозначить только углы части ⛶. Ещё такой подход позволит не путать часть с 
квадратом или прямоугольником, и тогда в части можно будет складывать фигуры:

```
⸢    ⸣  ⸢    ⸣  ⸢    ⸣
  □      △      ○   
⸤    ⸥, ⸤    ⸥, ⸤    ⸥.
```

А вот соответствующие этим фигурам слова: \[квадрат\], \[треугольник\], 
\[окружность\]. Оказалось, что в части можно даже вставлять текст, а на самом 
деле — всё что угодно или в нашем случае всё, что может быть графически 
обозначено на бумаге. Ещё частями можно заменить скобки и обозначение 
выражений, например: "((3+2)+6)" превращается в [[3+2]+6]. Сама по себе часть 
чем-то похожа на цитату и обозначается тоже 4-мя линиями, только ломаными: 
сравните "" и ⛶. Но бывает так, что мы имеем нечто целое, но разделённое на 
части, тогда и блок можно разделить:

```
⸢         ⸣  ⸢         ⸣  ⸢         ⸣
     ⛶           ⛶⛶         ⛶⛶⛶   
  1 часть      2 части      3 части
⸤         ⸥, ⸤         ⸥, ⸤         ⸥.
```

Причём больше всего это похоже на 1-3 части, состыкованные вместе, но граница 
между частями рисуется одна и общая.

Если вы сталкивались с таблицами, например в продукте от Microsoft — Excel или 
в терминах реляционных СУБД, то уже могли заметить, что такие части, состоящие 
из частей, начинают быть похожими на таблицы. Но и это ещё не всё, вы 
действительно сможете увидеть таблицы такого рода:

```
┌          ┬          ┐
    ⛶⛶        ▢▢ 
    ⛶⛶        ▢▢    
├          ┼          ┤
 составая    обычная
 часть с     таблица
 двумя       с двумя
 столбцами   столбцами
 и двумя     и двумя
 строками    строками
└          ┴          ┘
```

Как видите, часть на то и часть, что в неё даже можно вписать таблицы, но и в 
таблицы можно вставлять части. При этом сама часть может быть похожа на ячейку таблицы.
Итак, подведём итоги:

| Знак        | Его значение                                                           |
|-------------|------------------------------------------------------------------------|
| ⛶           | пустая часть                                                           |
| \[\[\]\]    | пустая часть, вписанная в другую часть                                 |
| ⛶⛶          | часть, состоящая из двух частей, например множество/последовательность |
| ⊞           | часть, состоящая из 4-х частей, например таблица, матрица              |


## Пустые связи

Пустые связи или связи состоящие из нуля ссылок на связи, это связи представляющие собой ничто, или отсутствие этих связей. Графически это можно выразить пустотою:

```
⸢                                                                                        ⸣
⸤                                                                                        ⸥
```

Причём в такой пустой части пространства может и не располагатся ни одной такой пустой связи, а так же это равносильно тому что в этой части располагается одна пустая связь, например сама эта часть. Пустота в ней и обозначает пустую связь, так же это равносильно и тому, что в этой части располагается бесконечное количество пустых связей. В общем, получается, что мы сразу графически рассмотрели все случаи изображения всех возможных пустых связей и сразу в любом их количестве. Причём эти пустые связи, если они там и есть могут располагаться в любом объёме пространства даже сколь угодно маленьком и даже в отсутствии пространства можно было бы разместить целую бесконечность пустых связей, но чтобы можно было графически ссылаться содержимое части необходимо заполнить хоть каким-то пространством, а для удобства его можно сделать не большим, как выше, а размером со строчный символ: ⛶, этого тоже будет достаточно, чтобы ссылаться на пустые связи или на их отсутствие, по своей сути смысл отсутствие связей или одной связи эквивалентен. Но сама часть при этом пустой является лишь от части. Т.е. часть полна пространством, но в ней нет графических обозначений чего либо, такое отсутствие графики внутри части и есть пустота. Иными словами не сама часть эквивалентна пустым связям, но пустота в ней. Однако две пустые части эквивалентны и равны: "⛶ <=> ⛶; ⛶ = ⛶" и с другой стороны не равны одновременно, так как "⛶ <> ⛶; ⛶ != ⛶" внутри каждой из пустой части может быть разное количество пустых связей. Само символическое обозначение ⛶ ссылается на "пустую часть", а пустота в этой части может означать и "пустые связи". Конечно у пустых связей может быть адрес, и можно обращаться к 1-й, второй и т.п. связям например так: \[①\], \[②\], и т.п. но всё они равны по смыслу, а значит: ⛶ = \[①\] = \[②\] и т.п.

В итоге хотя и можно множество пустых связей делить на элементы, каждый элемент равен любому другому и самому множеству/последовательности.

## Единичные связи

Единичные связи или связи состоящие из одной ссылки на другую связь.

Графически это может выражаться вот так:

...

Сама по себе связь содержащая ссылку на связь может представлять только два состояния: это либо связь-точка, т.е. она ссылается сама на себя, либо это связь-синоним. Синоним может быть прямым, т.е. например это 2-я и 6-я связь и косвенным это 7-я и 3-я связь. По своей структуре такие связи могут образовывать: "точки", "цепочки" и "деревья" и некоторые, но не все "графы" (? проверить ?), причём во всех случаях нельзя будет связать две отдельных точки или два отдельных синонима. А отсюда следует, что, такие связи не подходят для формирования самоопределяющихся последовательностей, и не могут представить через себя ни двойную связь, ни связи большей мерности.

Так как связи не обладают характеристикой размера их можно в бесконечном количестве расположить на сколь угодно малом пространстве, причём графически это может обозначить как заполненное краской пространство, так и одной лишь графической точки.

Если конечно внешне назначить каждой связи дополнительное значение, то, конечно можно использовать эти структуры для хранения "точек", "цепочек" и "деревьев" и некоторых "графов" (? проверить ?) с привязанными к ним значениями. Но сами единичные связи можно представить через двойные связи, например так:

...

\* в дальнейшем обозначение адреса связи примет свою однозначную форму, а именно ...4... и ...4...
\*\* единичные связи не могут иметь направления, кроме направления ссылок, которые они содержат

## Двойные связи

Двойные связи или связи смысл которых или значение состоящие из двух ссылок на другие связи.

Графически могут изображаться так:

...

1-"точка"; 4-"пара точек" 2 и 3; 3-"корень цепочки с элементом"2; 11-"внутреннее дерево" или "последовательность из 4-х элементов" 5, 6, 8 и 9; 12-"внешнее дерево"; 13 - "цикл" или "замкнутая цепочка из 3-х элементов" 17, 18 и 19.

В отличии от единичной связи двойная связь двойная связь связь может связывать любые другие две связи путём установки на них двух ссылок. Есть так же два варинта интерпретации связей, они могут быть направлены, тогда первая ссылка зовётся "началом", а последняя (в данном случае вторая) зовётся "концом"; они могут быть и не направлены, тогда обе ссылки равнозначны и дополнительного смысла кроме связывание двух в единое не несут. Есть отдельные случаи когда связь начинается в себе и в себе заканчивается, тогда направление в целом теряет смысл, потому что связь с обратным направлением это та же связь. Вне завимости от направления эти связи могут быть: "точками", "парами" и "частичными точками". "Частичной точкой" считается такая связь у которой только одна ссылка указывает на себя, а другая обязательно на другую связь. "Полной точкой" или просто "точкой" называется такая связь у которой обе ссылки указывают на себя саму. "Парой" называют такие связи обе ссылки которых указывают на другие связи. По своей структуре связи могут организовывать как внутренние, так и внешние структуры, тем самым покрывая любые возможные формы сетевых структур.

## Последовательности

Тройные связи и связи с N количеством ссылок на другие связи могут быть представлены в виде последовательностей, которые построены из двойных связей.

### Понятие "степени сжатия"

В ассоциативной памяти (сети) состоящей из двойных связей (пар) для построения строгой упорядоченной последовательности (частный случай множества элементов, а именно их размещения) требуется представлять элементы в виде структуры похожей на бинарное дерево (ациклический граф), где левым поддеревом или левой подпоследовательностью является начало связи, представляющей заданную последовательность, а правым поддеревом или правой подпоследовательностью является конец этой же связи. Деление на последовательность и подпоследовательность условно, подпоследовательностью называется составная часть последовательности, которая в то же время может представлять собой и самостоятельную последовательность.

Проще говоря последовательность либо сама есть элемент, либо стоит из двух других последовательностей.

```
На заметку:
Последнее определение рекурсивно, а значит уже включает все комбинации:
последовательность из двух элементов; последовательность из элемента и последовательности;
и последовательность из двух последовательностей.
```

Самим же размещением является положением элементов (листьев) дерева относительно друг друга слева на право или наоборот (в зависимости от принятого в системе направления за основное), при этом "высота", "уровень" или "глубина" расположения элементов игнорируется. Из этого следует, что любая структура дерева вне зависимости от его формы (структуры), но с определённым количеством элементов и самими элементами может представлять одну и ту же последовательность.

Например: последовательность "я" состоит из одного элемента (символа в данном случае) и представляется самим этим элементом: (я) или <ins>я</ins>; последовательность "да" состоит из двух элементов и представляется связью между ними (д)->(а) или <ins>да</ins>; последовательность "нет" состоит из трёх элементов и равнозначно может быть представлено двумя "деревьями" связей, а именно двумя связями: (н)->((е)->(т)) или <ins>н(ет)</ins> и ((н)->(е))->(т) или <ins>(не)т</ins>.

Продолжая приводить примеры подобные указанным выше, но содержащие большее число элементов начинают в точности соответствовать количеству и формам всех возможных вариантов деревьев для каждого количества элементов в отдельности и соответствует фактически последовательности [Каталановых чисел](https://ru.wikipedia.org/wiki/%D0%A7%D0%B8%D1%81%D0%BB%D0%B0_%D0%9A%D0%B0%D1%82%D0%B0%D0%BB%D0%B0%D0%BD%D0%B0) ([https://en.wikipedia.org/wiki/Catalan_number](Catalan Numbers)). Оценивая количество возможных построений последовательностей состоящих из 20 и более элементов легко прийти к выводу, что хранение всех возможных форм одной и той же последовательности на любом реальном физическом носителе, либо не имеет практического смысла, либо ввиду ограниченности доступных нам ресурсов невозможно с учётом такого ограничения. Не много в хранении всех её форм и теоретического смысла, ведь согласно первой аксиоме логики об идентичности "а=а", можно заключить что сам факт существования последовательности может запечатлён любой из его форм, так как из определения последовательности следует, что благодаря игнорированию "вертикальной" структуры они все эквивалентны одной и той же "горизонтальной" структуре.

```
Встаёт вопрос:
А как выбрать тот единственный вариант построения последовательности из всех возможных?
```

Иными словами, что лучше выбрать <ins>н(ет)</ins> или <ins>(не)т</ins>? Но прежде чем отвечать на такой вопрос оценим, а какие последствия нас ожидают, если мы на этот вопрос не ответим? Ведь не на всякий вопрос, возможно нужно отвечать...

Тут пожалуй всё просто, если мы сохраним все формы или хотя бы по две из них для каждой последовательности мы во-первых вводим систему (множество последовательностей) в противоречие с первой аксиомой логики (об идентичности) и всегда имеем ситуацию, когда у нас есть больше одной и той же по своему смыслу последовательности, т.е. "а!=a". С другой стороны и во-вторых при хранении на физическом носителе можно крайне быстро исчерпать весь ресурс доступного "информационого" или "адресного" пространства. Ну а манипуляция такими объёмами памяти приведёт так же к большим затратам по времени исполнения операций записи и чтения.

Пожалуй достаточно оснований для того, чтобы заранее поставить этот теоретический вопрос?

Чтобы выбор был оптимальным с точки зрения приведённых выше последствий, нужно, чтобы все из этих "негативных" последствий были сведены к минимумму. А значит оптимальной будет ситуация, когда каждая последовательность и следовательно каждая "подпоследовательность" будет существовать минимальное число раз, а в нашем случае это фактически 1, т.е. ровно один раз. И желательно в каждый момент времени до и после каждой операции над последовательностями в экземпляре ассоциативной памяти. Чем фактически будет обеспечено минимально возможное использование физического пространства на информационном носителе.

Так же будет сведён к минимуму объём вычислительных мощностей требуемых для чтения и записи (трансформации) последовательностей, если не считать неизбежную жертву в такой ситуации - память и время вычисления, которые будут направлены на выбранный аппарат хранения, структуризации и трансформации этих последовательностей.

Для оценки качества или близости к оптимальному случаю (ситуации) мы и введём понятие "степень сжатия последовательности". На практике могут опускаться некоторые требования оптимальной ситуации для экономии или более эффективного использования ресурсов. Например можно допускать дубликаты в то время, пока от системы требуется максимальная отзывчивость (скорость реакции), а "упаковку", "сжатие" или "структуризацию" откладывать на время "сна" системы, т.е. времени в течении которого реакция на внешнюю среду не требуется. Это чем-то похоже на остановку выполнения при "сборке мусора" в средах поддерживающих объектно-ориентированный подход.

Позволим себе некоторое отступление от темы. Вообще проблема выбора, сама по себе имеет очень глубкие исторические корни, например до сих пор существуют различные языки, которые можно разделить однозначно на две категории: использующие направление записи слева на право, так и справа на лево. Хотя с другой стороны при чтении в слух или при переводе из письменного в акустический носитель можно заметить, что ранее разделённые по направлению написания сигналы получаются едины в направлении произношения. Причём эта же проблема выбора имеет отражение и в ассоциациях с добром и злом, жизнью и смертью, "походом налево" и "православием" и т.п. Хотя и здесь события являются шаблоном трансформации, но в зависимости от набора аксиом (принимаемых за истину вариантов формы отношения к фактам/событиям) может быть оценено совершенно по разному, при том, что сама трансформация и её направление (шкала времени) остаётся неизменнной относительно всех "наблюдателей", ещё такое называют "объективным, а отношение каждого наблюдателя субъективным. Ещё субъективной формой отношения к событиям (частичным трансформациям) называется интерпретация т.е. в данном случае "отношение" подразумевает процесс изменения (модификации) воспринимаемого носителя информации для формирования точного образа (модели), или можно сказать восстановление, распаковка передаваемой/воспринимаемой модели в сознании (оперативной памяти, оперативном состоии системы) субъекта, до необходимого уровня детализации, для использования в процессе реализации целей субъекта, с допустимым уровнем искажения исходного события. Причём первичное искажение вносится добавлением субъективной оценки или вывода возникающего при сравнении с аксиомами принимаемым за истину, которые не редко выводятся из "эталона", "примера", "образца", "традиции", иначе говоря некоторого шаблона трансформации, который субъектом принимается за "достойный" повторения или "необходимый" к повторению для приведения окружающей его части глобальной трансформации к желаемому "виду", форме, шаблону, и за счёт повторения фактически усилиями субъекта приводимый в относительно "неизменное состояние", "постоянное состояние".

Причём есть общая, глобальная трансформация не является зависимой от субъекта полностью, то при продолжении применения некоторого шаблона действий он фактически приводит к некоторому образцу лишь часть эффектов общей трансформации, либо лишь отдельные аспекты того, что его окружает. Если же воздействие субъекта прекращается то желаемый шаблон формы может быть утерян, если не осталось больше носителей такого жалаемого шаблона, но если воздейсвие было достаточно длительно, обширно или ярко/контрастно, у такого шаблона действий (примера) и такого шаблона формы (цели) в таком шаблоне окружения (истока) может образовываться множество дополнительных носителей шаблона действий, которые либо уже вошли в "привычку", либо являются единственным оптимальным выходом (целью) из сложившегося шаблона окружения (истока).

Такие дополнительные носители обычно называются "последователи", а шаблон действий "традицией".

Возвращаясь к теме определения "степени сжатия", попробуем описать его более формально (точнее). Для этого возьмём два крайних случая - последовательность из одинаковых элементов и из уникальных относительно друг друга элементов. Для примера будем использовать всего 4 элемента: \[○\] \[△\] \[□\] \[☆\]. Из этих элементов составим две последовательности: \[○\] \[○\] \[○\] \[○\] и \[☆\] \[○\] \[□\] \[△\].

Такие последовательности выбраны не случайно, только при длине в 4 элемент начинает проявляться эффект "сжатия" внутри (контексте) одной последовательности. Последовательности длиною в 1-3 элемента ведут себя одинаково вне зависимости от содержания:

...

Иными словами все характеристики последовательности и её структуры остаются одни и те же, даже при различном содержании элементов в последовательности.

Под "всеми характеристиками" имеются ввиду: высота структуры последовательности (В), длина последовательности или количество элементов в последовательности (Д) и количество возможных вариантов (способов) построения дерева, представляющего структуру последовательности (П).

Итак рассмотрим теперь последовательности с длиной равной четырём элементам.

У обоих вариантов будет по 5 способов построения. Фактически "П" всегда зависит только от "Д". Мы не будем вдаваться во все возможные варианты построения, а возьмём для каждого из двух вариантов содержание последовательности с длиной 4 по два крайних случая, назовём их "сжатый" и "несжатый". И введём ещё одну характеристику для оценки - количество связей необходимых на саму структуру дерева, представляющего эти последовательности (С).

...

Как видно из примеров, теперь характеристика (С) зависит от содержимого последовательности, если каждая пара существует в ассоциативной памяти только один раз, то в случае с одинаковыми элементами появляется так же и одинаковые пары, например \[○\] \[○\] используется дважды. А вот в случае уникальных элементов одинаковых пар не образуется. А именно появление и повторное использование одни и тех же пар приводит к экономии пространства под необходимое для структуры количество связей (С).

Можно так же заметить, что в случае последовательности состоящей из уникальных элементов количество связей на структуру не будет зависеть от самой формы этой структуры:

...

Однако при выборе структуры ещё можно сократить высоту, но относительно "степени сжатия" данный случай называется "несжимамаемым" и обусловлен тем, что внутри последовательности все элементы уникальны друг относительно друга. С другой стороны если какие либо пары последовательности внутри экземпляра ассоциативной памяти не уникальны, т.е. используются например двумя разными последовательностями, то даже в этом, казалось бы "худшем случае" возможно сжатие, т.е. частичнае или полное повторное использование которое и проводит к экономии свободного пространства.

...

В этом примере \[☆\] \[○\] используется дважды, и тем самым мы получаем сжатие на 1 связь, т.е. экономию одной связи в свободном пространстве. Хотя если бы обе последовательности хранились отдельно, потребовалось бы 6, а не 5 связей.

Отсюда следует вывод, что "сжатием" мы называем количество "съэкономленных связей", а вот "степенью сжатия" будем считать соотношение "худшего" возможного случая при организации структуры последовательности к текущему варианту, а само значение степени будем выражать в "%" или долях т.е. например "степень сжатия" в последнем примере это 5/6 или (100/6 * 5)% = 83,3(3)% = 83,(3)%. "Лучшим" же возможным случаем в альтернативу приведённого примера будет "объединение" двух одинаковых последовательностей в одну и использование одинаковых элементов вместо уникальных, что при "двух" последовательностях будет 2/6, а если бы это была одна последовательность из 4-х элементов, то 2/3. Степень сжатия на иллюстрации можно обозначить как СС*.

* Степень сжатия в примерах введена одновременно с написанием этого примечания.

Получается, что есть два схожих термина: "степень сжатия совокупности последовательностей" и "степерь сжатия отдельной последовательности". Ещё второй термин можно обозначить как "самостоятельная степень сжатия последовательности". Но в обоих случаях чем меньшей долью целого выражается степень сжатия, тем больше свободного пространства мы экономим, т.е. сохраняем для более эффективного использования.

### Алгоритмы построения последовательностей

#### Лесенка

Алгоритм построение последовательностей в ассоциативной памяти, состоящий из парных связей: "последовательный вариант", "лесенка", или "список".

Тестирование алгоритма происходит на примере "длинной" и "коротких" последовательностей, но в контексте одного экземпляра памяти.

1. Создадим "длинную" последовательность

...

2. Создадим "короткие" последовательности входящие в "длинную"

а)
...

Все связи уже существовали, поэтому дополнительных связей создавать не потребовалось. Иными словами, если у последовательностей общее в точности начало, на построение структуры новых связей тратить не требуются.

б)
...

Две связи уже существовали, однако потребовалось ещё 4. Хотя по факту, они избыточные, так как существует такая структура, при которой при создании подпоследовательностей уже входящих в существующую, при которой никаких новых связей не потребуется.

в)
...

4 связи уже были, 1 добавилась.

##### Итоги и выводы

Всего "создавалось" или "вносилось в ассоциативную память" 4 последовательности, 3 из которых входят в 4-ю последовательность. Итого было внесено последовательностей общей длиной (23+7+8+6), т.е. 44 "символа" или "элемента". Всего использовалось уникальных элементов-символов: "з", "е", "ё", "л", "н", "а", " ", "я", "ь". Т.е. 9 штук, что означает что для их хранения нужно не менее 9 связей. Итого на символы и последовательности ушло 9+27 связей. 27 связей ушло на организацию структуры последовательностей. Исходя из того, что в худшем случае (при пустой ассоациативной памяти или отсутствии повторно используемых пар, а в случае данного алгоритма достаточно отсутствия первой пары последовательности, чтобы она создавалась "худшим образом/случаем", т.е. каждая связь необходимая для организациии структуры последовательности была создана вновь и ни одна не была использована повторно) на построение последовательности уходит на одну связь меньше чем общее число элементов в последовательности, а именно в данном случае: ((23-1)+(8-1)+(7-1)+(6-1)) = 40 связей. Если степень сжатия соотношение количествая связей в частном случае по отношению к худшему случаю при организации структуры последовательностей, то в нашем случае общей степенью сжатия будет 27/40 = 13,5/20 = 6,75/10 = 67,5%

Стоит заметить, что хотя этот алгоритм и является олицетворением или точнее сказать синонимом "худшего случая" при отдельном рассмотрении каждой последовательности, но при совокупном рассмотрении даже этот алгоритм выдаёт достаточно высокую степень сжатия, хотя конечно с некоторой вероятностью, которая зависит от структуры конкретных последовательностей и наличия у них общих частей, а именно общих начал (или концов, в зависимости от ориентации применения алгоритма).

#### Балансированный вариант

"Длинные" и "короткие" последовательности на примере "балансированного варианта".

1. Создади "длинную" последовательность

...

2. Создадим "короткие" последовательности входящие в "длинную"

а)
...

Пока всё "замечательно": каждая пара из "короткой" подпоследовательности, входящей в "длинную" уже существовало и новых связей, представляющих пары создавать не потребовалось.

б)
...

Здесь уже "не всё так чудесно", одна пара уже существовала, но потребовалось создать её 5 связей.

в)
...

3 связи уже были, 2 добавилось.

##### Итоги и выводы

Всего "создавалось" или "вносилось в ассоциативную память" 4 последовательности, 3 из которых входят в 4-ю последовательность. Итого было внесено последовательностей общей длиной (23+7+8+6), т.е. 44 "символа" или "элемента". Всего использовалось уникальных элементов-символов: "з", "е", "ё", "л", "н", "а", " ", "я", "ь". Т.е. 9 штук, что означает что для их хранения нужно не менее 9 связей. Итого на символы и последовательности ушло 9+26 связей. 26 связей ушло на организацию структуры последовательностей. Исходя из того, что в худшем случае (при пустой ассоациативной памяти или отсутствии повторно используемых пар, а в случае данного алгоритма достаточно отсутствия первой пары последовательности, чтобы она создавалась "худшим образом/случаем", т.е. каждая связь необходимая для организациии структуры последовательности была создана вновь и ни одна не была использована повторно) на построение последовательности уходит на одну связь меньше чем общее число элементов в последовательности, а именно в данном случае: ((23-1)+(8-1)+(7-1)+(6-1)) = 40 связей. Если степень сжатия соотношение количествая связей в частном случае по отношению к худшему случаю при организации структуры последовательностей, то в нашем случае общей степенью сжатия будет 26/40 = 13/20 = 6,5/10 = 65%

Этот алгоритм выдаёт достаточно высокую степень сжатия, с некоторой вероятностью, которая зависит от структуры конкретных вносимых последовательностей, а именно от наличия у них общих частей, причём большее число общих частей возможно в том случае, если направление разбиения последовательности на пары совпадает с направлением разбиения уже ранее созданной части. Или иными словами для совпдания частей и составных из них, требуется чтобы разбиение на пары у обоих частей начиналось либо у обоих с конца к началу, либо у обоих с начала к концу, иначе совмещение и повторное использование будет невозможно и породит дополнительный дубликат.
