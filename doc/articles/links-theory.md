# Черновик Теории Связей
## Вступление
Середина XX века связана с появлением единой теории универсальных вычислительных машин, называемых сегодня "Машинами Тьюринга".
Название это сегодня в начале XXI века стало нарицательным и является синонимом любого вычислительно устройства в связи с широким признанием этой теории обществом. Именно эта технология вдохновила технических специалистов по всему миру на активное развитие вычислительной техники. Именно Аланом Тьюрингом в то же время был поставлен вопрос о том, может ли мыслить машина и о том, а не является ли человек машиной. Всё это привело к началу активного исследования вопроса о возможности создания искусственного интеллекта (ИИ), неотличимого от интеллекта человеческого. И хотя сравнение таких комплексных систем возможно лишь в ограниченной степени, и часто происходит лишь на узком круге задач, таких как ведение беседы между двумя интеллектами или ведение игры и т.п., всё же успехи в этой области есть и с каждым годом их количество увеличивается, а качество повышается. Всё это шаг за шагом ведёт к тому, что мы лучше понимаем себя, узнаём новые возможности и ограничения интеллекта человеческого, и перенося полученные знания в теорию вычислительных машин с каждым разом всё глубже проникаем в суть того как эти внешние эффекты, возможности, ограничения можно воспроизвести в рукотворном интеллекте, как именно это всё может быть устроено изнутри, и всё это шаг за шагом приближает нас к созданию новых технических систем, которые улучшая старые образцы всё ближе подходя к тому, что можно назвать интеллектуальным, разумным, умным, однажды и завершится той самой точкой сингулярности, когда будет создана такая мыслящая система, которая сможет улучшать и развивать сама себя и сможет решать любую задачу, которую поставит ей человек, в том числе и создание автономного искусственного интеллекта со своей волей, т.е. самостоятельно определяющего свои цели - так называемый интеллект сильного типа. У "искусственного интеллекта сильного типа" могут быть и эмоции, что с одной стороны позволило бы лучше ему понимать нас, людей, как мы воспринимая эмоции друг друга лучше понимаем друг друга, с другой стороны позволило бы и нам ещё глубже понимать себя самих и то как мы устроены. Но ИИ сильного типа не обязательно создавать напрямую, его может однажды создать ИИ слабого типа, который сам и не будет обладать своей волей, но если ИИ слабого типа будет создан, то цель ему может быть поставлена человеком. Поэтому можно сказать, что ИИ слабого типа будет достаточно, чтобы привести к существованию рано или поздно ИИ любого типа, любой сложности, с любой мощностью и с любым набором "встроенных" характеристик. 
Важно так же осознавать что есть различные риски для общества в связи с развитием подобных технологий. Так же как и у других результатов технологического прогресса всё будет определено тем, кто и как будет применять эти результаты. Для того же кто последует путём разработки следует дать рекомендацию, что вероятнее всего ИИ сильного типа будет необходимо содержать в изоляции от общества и окружающей среды, постепенно и под контролем снимая ограничения. Такой контроль и осуществление ограничений установленных человеком сможет осуществлять ИИ слабого типа, человек же успеть среагировать скорее всего уже не сможет. Это похоже на то, как контроль осуществляется родителями над ребёнком в семье и на то как контроль осуществляется законом в обществе над каждым его гражданином. Авторов этой теории интересовал в первую очередь вопрос понимания того что такое интеллект, из чего он состоит и следовательно без чего он не может существовать. Так же как машина Тьюринга не может быть вычислителем без наличия ленты с нулями и единицами, так же и интеллект не может существовать без памяти. С одной стороны можно поставить равенство между "лентой машины Тьюринга" и "памятью" любого интеллекта. Тогда в сущности получится, что интеллект есть ни что иное как вычислительная машина. Тогда уже сегодня существует множество "искусственных интеллектов", получается ли тогда что и "точки сингулярности" мы уже достигли? Пожалуй нет. Может ли сегодня любая вычислительная машина самостоятельно, без программиста адаптировать себя под окружающую среду, определить или вспомнить свою цель, сравнить окружение с целевым образом, и если различия всё ещё присутствуют продолжить их устранять? Пусть и не любая, тогда существует ли хотя бы одна такая машина сегодня? Иначе этот критерий можно сформулировать так: Существует ли машина заранее не запрограммированная на решение задачи, которая если ей такое описание задачи предоставить, смогла бы за приемлемое время составить, найти, или иными способами сгенерировать алгоритм или последовательность действий, решающих эту задачу так, чтобы это удовлетворило бы постановщика задачи?
Такой критерий может соответствовать "искусственному интеллекту слабого типа". Для "ИИ сильного типа" этот критерий можно усложнить тем, что помимо решения любых решаемых задач (см. проблему остановки Машины Тьюринга) такая машина в качестве одной из задач, постоянно решаемых, должна будет включать задачу поддержания своей "жизни", т.е. сохранять свою интеллектуальную функцию автономно, т.е. самостоятельно, независимо от человека, а помимо этого такая машина должна самостоятельно для себя решать, какие цели или задачи она будет решать "дополнительно". Причём подобная постановка критерия приведёт к тому, что "ИИ сильного типа" будет подвержен "естественному отбору" так же как и любое живое существо биологического типа, в основе которого ДНК-программа. Вероятно и для "ИИ сильного типа" потребуется подобрать "ДНК-программу", определяющую его "тело" и "разум", в который должна быть встроена "программа заботы о теле" или "программа саморепликации". Если первая "минимальная программа" спровоцирует создание "вечно живущего" разума, то вторая спровоцирует создание целой популяции разумов "размножающихся делением". Такую "минимальную" программу для "ИИ сильного типа" мог бы аналитически вывести или генетически подобрать (вырастить), а так же протестировать в ограниченной среде или в реальной среде но с ограничениями уже "ИИ слабого типа". Тестирование какого либо "ИИ" не вводя ограничений может привести к непредсказуемым последствиям. С того момента, когда найдётся тот, кто все ограничения снимет мы однозначно перейдём в эпоху, момент перехода в которую и называют "точкой сингулярности". Есть риски действия, есть риски и бездействия. Уже сегодня многие крупные корпорации начали гонку за лучший "сервис" и тем или иным способом внедряют элементы "интеллектуальных" систем, контроль за которыми сегодня осуществляют программисты. Возможно и государства занимаются чем-то подобным. Суть в том, что вычислительные машины уже сегодня есть у всех, и если кто-то однажды угадает тот заветный "минимальный алгоритм" "точка сингулярности" сама по себе наступит непредсказуемо быстро. Если у нас не будет систем быстрого реагирования и защиты от высокоинтеллектуальных систем, мы рискуем за кратчайший срок получить либо значительный ущерб, либо потерять контроль над неопределённой заранее по размерам части доступных нам вычислительных ресурсов, что как и первое может привести всё к тем же непредсказуемым последствиям. Чем-то контролирующая система похожа на антивирус, а вот "объект исследований" "ИИ сильного типа" на вирус. И то и другое действует в некоторой степени автономно, "контролирующая" система собственной волей не обладает, "исследуемая" система тоже своей волей обычно не обладает, однако самостоятельно поддерживает свою жизнедеятельность. Иными словами "ИИ слабого типа" чем-то похож по внешним признакам на сегодняшние антивирусы, а "ИИ сильного типа", развивающийся путём "размножения делением", а так же путём самомодификации будет иметь много общего с вирусами сегодняшнего дня. Все эти общее признаки в сегодняшнем объёме знаний человечества одному человеку увидеть и понять может быть затруднительно. Но всё же технология требует глубокого понимания, чтобы осознать её мощь и возможности, а так же зная её "слабые места" возыметь силу её обуздать. Ведь даже сегодня антивирусы способны бороться с тем, что уже однажды нанесло ущерб, а что если бы антивирус мог бы самостоятельно выработать защиту от заранее неизвестной угрозы, которая начала наносить вред или только готовится его нанести? Ведь это могло бы предотвратить больше ущерба, и в свою очередь в будущем не позволило бы и различным "ИИ сильного типа" воспользоваться слабыми местами сегодняшних вычислительных систем? Что если бы вместо программистов уязвимости, пусть даже какую-то её часть устраняли бы автоматизированные роботы-программисты? Это позволило бы быстрее реагировать на угрозы. Уже сегодня чувствуется необходимость в системах реагирующих быстрее человека, однако обладающих гибкостью подобной человеческой. Мы утопаем в море информации на разных языках, которая всё ещё медленно переводится и увеличивается то время, которое проходит до качественного использования этой информации каждым человеком на планете. Уникальные идеи сложно находить. А работы по актуальным времени задачам многократно дублируются на разных языках независимо друг от друга, что негативно сказывается на темпах развития человечества в целом, замедляя эти самые темпы. До сих пор статьи в Википедии не синхронизированы и не приведены к единому виду с переводами на все языки, что заставляет читателя сравнивать статьи с одним и тем же по смыслу корнем, названием между языками. Опыт различных культур всё ещё ограничено доступен носителям других культур и языков. Тем временем расслоение наблюдается и в языках программирования и разделяется следовательно и сообщество людей, одни и те же задачи решаются по разному на разных языках программирования, и одно единое решение не вырабатывается или вырабатывается но очень медленно. Видится огромный пласт задач и проблем на решение которых не мешало бы направить искусственный интеллект, освободить тем самым руки и внимание людей уже под задачи более высокого уровня.
Да всё это сегодня развивается в среде, которую нам предоставила физическая реализация "Машины Тьюринга" в сегодняшних компьютерах. Но это требует особой категории людей - программистов для развития. А так как таких людей не хватает, сегодняшние корпорации вынуждены закрывать код, придумывать способы продать эту закрытую технологию и обеспечить тем самым доходом программистов. Да и программисты здесь неизбежный на данном этапе элемент. Их ещё никто не автоматизировал, и следовательно, так как им нужны деньги, чтобы они продолжали работать развитие технологий медленное и имеет высокую стоимость. И простая жадность мотивирует защищать капитал, т.е. код закрывая его от публики, помогая сохранить конкурентное преимущество, но замедляя развитие остальной части человечества. Примеры целой группы/класса проблем можно перечислять очень долго, ещё дольше можно рассуждать, а к чему к какому ускорению развития привело бы решение целого класса задач. И для приближения качественного решения другого уровня, т.е. ИИ, кажется, требуется провести ретроспективу, т.е. пересмотр того, а к чему собственно привело введение в обиход Машин Тьюринга. Каждый день сегодня в работе программисту требуется долго и мучительно адаптировать казалось бы очевидное решение под конкретное окружение и конкретную архитектуру. Подбирать множество разных структур данных, если выбор стоит в плоскости независимой разработки, учитывать особенности железа и проверять, чтобы код превращался в нужный набор инструкций, чтобы достичь высокого уровня производительность. И ведь всё это происходит на "универсальной машине Тьюринга", где не нужно переделывать машину под каждую задачу, а достаточно переделать только код машины. Кажется, этой модели не хватает чего-то. По крайней мере так оно и выглядело для авторов несколько лет назад, когда выполнялся поиск подходящей среды для экспериментов в области искусственного интеллекта. Самыми близкими к требуемым критериям универсальности, гибкости и простоты были Lisp-системы и Lisp-машина, вводящие универсальные списки, последовательности и СУБД построенная на основе ассоциативной модели памяти Sentences, разработанная Симоном Вильямсом, вводящая тройные связи по модели Субъект-Глагол-Объект. И эти связи в отличии от рёбер теории графов вносили важную модификацию. Связи могли ссылаться на связи, позволяя тем самым строить структуру предложений любой сложности для эффективной работы с данными на "семантическом уровне". Но по инерции из теории графов были переняты "точки" или "элементы", к которым и привязывались текстовое описания (значение этих элементов), те самые последовательности, списки символов. Изначально было принято решение, ввиду закрытости исходного кода Sentences, упростив модель разработать своё открытое технологическое решение. Так связям было разрешено ссылаться и нам самих себя. А точки "элементы" были полностью исключены из системы. В ходе экспериментов было показано, что можно хранить текстовые последовательности внутри "Связей". Так тогда назывался проект. Это означало, что модель прошла проверку и от Sentences можно отказаться, новая модель проще и гибче. И включает в себя тот же функционал, не теряя из него ни одной возможности, которую предоставляла исходная закрытая система. Так же следует подчеркнуть, что в противоположность "закрытому коду" выбран путь развития через "открытый код", что само по себе упрощает переориентировку на всё человечество в целом, в противоположность ряду закрытых групп людей и сообществ.
